\title{Project Proposal: CS281, Fall 2017}
\author{Brian Hentschel, Anna Sophie Hilgard, Casey Meehan}

\date{\today}

\documentclass[a4paper, 11pt]{article}
\usepackage{float}
\usepackage{graphicx}%
\DeclareGraphicsExtensions{.pdf,.eps,.png}
\begin{document}
\maketitle


\section{Problem Statement}
\subsection{Peer Prediction} 
\paragraph{}The general problem of peer prediction concerns creating mechanisms to incentivize honest forecasts and feedback from crowd workers. The main line along which peer prediction tasks are split is ``ground truth" vs. ``no ground truth". In scenarios with ground truth, there are methods such as ``gold standard reports" which may often be used to conclusively determine effort and quality of reports, but these may be too costly to generate. In scenarios with no ground truth, we often have no better option than to use manipulations on the reports themselves to determine the quality of the other reports. 
\paragraph{}However, the no ground truth problem inherently prohibits many peer prediction mechanisms, as diversity of opinions will be interpreted as incorrectness. For example, if we were to judge the quality of Google reviews by whether the reports agreed with other Google reviews, truthful minority opinions would be penalized. This leads us to believe that a more complicated heterogeneous-user mechanism is required.
\subsection{Global Forecasting} 
\paragraph{}

\section{Approach}

\section{Evaluation}

\section{Collaboration Plan}

\section{Double Dipping}

\end{document}