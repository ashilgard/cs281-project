{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from itertools import combinations_with_replacement\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering, AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gj = pd.read_csv('./gj_df.csv')\n",
    "# gj = gj[['ifp_id', 'ctt', 'cond', 'training', 'team', 'user_id', 'value', 'fcast_date']]\n",
    "# gj['fcast_year'] = pd.to_datetime(gj['fcast_date']).dt.year\n",
    "# gj['fcast_week'] = pd.to_datetime(gj['fcast_date']).dt.week\n",
    "# gj['ifp_week'] = gj['fcast_year'].map(str) + gj['fcast_week'].map(str) + gj['ifp_id']\n",
    "# gj = gj.drop('fcast_date', axis=1)\n",
    "# gj = gj.drop_duplicates()\n",
    "# gj.to_csv('./gj_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ifp_id</th>\n",
       "      <th>ctt</th>\n",
       "      <th>cond</th>\n",
       "      <th>training</th>\n",
       "      <th>team</th>\n",
       "      <th>user_id</th>\n",
       "      <th>value</th>\n",
       "      <th>fcast_year</th>\n",
       "      <th>fcast_week</th>\n",
       "      <th>ifp_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>201551244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>201561244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>201571244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>201581244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>201581244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>201591244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1394-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2014</td>\n",
       "      <td>42</td>\n",
       "      <td>2014421394-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1394-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2014</td>\n",
       "      <td>43</td>\n",
       "      <td>2014431394-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ifp_id ctt  cond training  team  user_id  value  fcast_year  fcast_week  \\\n",
       "0  1244-0  1a     1        a   NaN       51   0.20        2015           3   \n",
       "1  1244-0  1a     1        a   NaN       51   0.20        2015           4   \n",
       "2  1244-0  1a     1        a   NaN       51   0.20        2015           5   \n",
       "3  1244-0  1a     1        a   NaN       51   0.20        2015           6   \n",
       "4  1244-0  1a     1        a   NaN       51   0.20        2015           7   \n",
       "5  1244-0  1a     1        a   NaN       51   0.20        2015           8   \n",
       "6  1244-0  1a     1        a   NaN       51   0.09        2015           8   \n",
       "7  1244-0  1a     1        a   NaN       51   0.09        2015           9   \n",
       "8  1394-0  1a     1        a   NaN       51   0.75        2014          42   \n",
       "9  1394-0  1a     1        a   NaN       51   0.75        2014          43   \n",
       "\n",
       "       ifp_week  \n",
       "0   201531244-0  \n",
       "1   201541244-0  \n",
       "2   201551244-0  \n",
       "3   201561244-0  \n",
       "4   201571244-0  \n",
       "5   201581244-0  \n",
       "6   201581244-0  \n",
       "7   201591244-0  \n",
       "8  2014421394-0  \n",
       "9  2014431394-0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adult = pd.read_csv('../labels.txt', delimiter='\\t', header=0, names=['user_id','website','rating'])\n",
    "# trec = pd.read_csv('../trec-rf10-crowd/trec-rf10-data.txt', delimiter='\\t')\n",
    "# gj = pd.read_csv('./filled_active_df.csv')\n",
    "\n",
    "# best_users = trec.groupby('workerID').count().sort_values('docID', ascending=False)[:150].index\n",
    "# trec = trec[trec['workerID'].isin(best_users)]\n",
    "\n",
    "# r = pd.Series([2,3,2,3], index=[1,2,0,-2])\n",
    "# trec['label_bin'] = trec['label'].map(r)\n",
    "gj.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ifp_id</th>\n",
       "      <th>ctt</th>\n",
       "      <th>cond</th>\n",
       "      <th>training</th>\n",
       "      <th>team</th>\n",
       "      <th>user_id</th>\n",
       "      <th>value</th>\n",
       "      <th>fcast_year</th>\n",
       "      <th>fcast_week</th>\n",
       "      <th>ifp_week</th>\n",
       "      <th>bin</th>\n",
       "      <th>task_id</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>201551244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>201561244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>201571244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ifp_id ctt  cond training  team  user_id  value  fcast_year  fcast_week  \\\n",
       "0  1244-0  1a     1        a   NaN       51    0.2        2015           3   \n",
       "1  1244-0  1a     1        a   NaN       51    0.2        2015           4   \n",
       "2  1244-0  1a     1        a   NaN       51    0.2        2015           5   \n",
       "3  1244-0  1a     1        a   NaN       51    0.2        2015           6   \n",
       "4  1244-0  1a     1        a   NaN       51    0.2        2015           7   \n",
       "\n",
       "      ifp_week  bin  task_id  uid  \n",
       "0  201531244-0  0.2        0    0  \n",
       "1  201541244-0  0.2        1    0  \n",
       "2  201551244-0  0.2        2    0  \n",
       "3  201561244-0  0.2        3    0  \n",
       "4  201571244-0  0.2        4    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testframe = create_user_task_ids(adult, 'user_id', 'website', 'rating')\n",
    "testframe = create_user_task_ids(gj, 'user_id', 'ifp_week', 'value', False, True)\n",
    "testframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.cut(\n",
    "    testframe['value'],\n",
    "    [-np.inf, .2, .4, .6, .8, np.inf],\n",
    "    labels=[2,3,5,7,11]\n",
    ")\n",
    "testframe['bin_levels'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testframe = testframe[testframe['uid']<1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def split(df):\n",
    "    train_df, validate_df, test_df = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "    return train_df, validate_df, test_df\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, users, tasks, k=2):\n",
    "        super(Model, self).__init__()\n",
    "        self.user_lut = nn.Embedding(users, k)\n",
    "        self.task_lut = nn.Embedding(tasks, k)\n",
    "\n",
    "        self.user_bias = nn.Embedding(users, 1)\n",
    "        self.task_bias = nn.Embedding(tasks, 1)\n",
    "        self.global_bias = nn.Parameter(torch.FloatTensor(1))\n",
    "        \n",
    "    def forward(self, users, jokes):\n",
    "        user_vectors = self.user_lut(users)\n",
    "        task_vectors = self.task_lut(jokes)\n",
    "        user_bias = self.user_bias(users)\n",
    "        task_bias = self.task_bias(jokes)\n",
    "\n",
    "        return torch.bmm(user_vectors.unsqueeze(1),\n",
    "                         task_vectors.unsqueeze(2)).squeeze() \\\n",
    "                         + user_bias.squeeze() + task_bias.squeeze() + self.global_bias.expand_as(user_bias.squeeze())\n",
    "\n",
    "def val(df, model):\n",
    "    crit = nn.MSELoss(size_average=False)\n",
    "    total_loss = 0.\n",
    "    total_num = 0\n",
    "    for batch in batcher(df, 100):\n",
    "        true_rating = Variable(torch.Tensor(batch.bin.values.astype(float)))\n",
    "        total_num = total_num + true_rating.size(0)\n",
    "        users = Variable(torch.LongTensor(batch.uid.values))\n",
    "        tasks = Variable(torch.LongTensor(batch.task_id.values))\n",
    "        scores = model.forward(users, tasks)\n",
    "        total_loss += crit(scores, true_rating).data[0]\n",
    "    return math.sqrt(total_loss/total_num)\n",
    "\n",
    "\n",
    "def train(train_iter, val_iter, test_iter, model):\n",
    "    opt = optim.SGD(model.parameters(), lr=0.1)\n",
    "    crit = nn.MSELoss()\n",
    "\n",
    "    print(\"val:\", val(validate_df, model))\n",
    "    for epochs in range(30):\n",
    "        avg_loss = 0\n",
    "        total = 0\n",
    "        for i,batch in enumerate(batcher(train_df, 100)):\n",
    "            opt.zero_grad()\n",
    "            rating = Variable(torch.Tensor(batch.bin.values.astype(float)))\n",
    "#             print(rating)\n",
    "            users = Variable(torch.LongTensor(batch.uid.values))\n",
    "            tasks = Variable(torch.LongTensor(batch.task_id.values))\n",
    "            scores = model.forward(users, tasks) \n",
    "#             + torch.sum(model.user_lut.weight.data.pow(2)) + \\\n",
    "#             torch.sum(model.task_lut.weight.data.pow(2)) + torch.sum(model.user_bias.weight.data.pow(2)) + \\\n",
    "#             torch.sum(model.task_bias.weight.data.pow(2))\n",
    "            loss = crit(scores, rating)\n",
    "            #if i % 1000==0:\n",
    "            #    print (loss.data[0])\n",
    "            loss.backward()\n",
    "            avg_loss += loss.data[0]\n",
    "            total += 1\n",
    "            opt.step()\n",
    "        print(\"train:\", math.sqrt(avg_loss / float(total)))\n",
    "        print(\"val:\", val(validate_df, model))\n",
    "        print(model.user_bias.weight.data)\n",
    "    return model.user_lut.weight.data, model.user_bias.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: 2.0344810784346175\n",
      "train: 1.319820234437903\n",
      "val: 0.8708446363039286\n",
      "\n",
      "-0.9573\n",
      "-0.2501\n",
      "-0.1474\n",
      "   ⋮    \n",
      " 1.3903\n",
      "-0.1703\n",
      "-0.0891\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.6830325764679976\n",
      "val: 0.547055658469096\n",
      "\n",
      "-0.5904\n",
      "-0.1287\n",
      "-0.1246\n",
      "   ⋮    \n",
      " 0.8646\n",
      "-0.0031\n",
      "-0.0069\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.4591340022909762\n",
      "val: 0.4031205534734756\n",
      "\n",
      "-0.3352\n",
      "-0.1165\n",
      "-0.1055\n",
      "   ⋮    \n",
      " 0.6189\n",
      " 0.0340\n",
      " 0.0253\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.35502289407552784\n",
      "val: 0.33101080138363626\n",
      "\n",
      "-0.1583\n",
      "-0.1185\n",
      "-0.0901\n",
      "   ⋮    \n",
      " 0.4998\n",
      " 0.0422\n",
      " 0.0366\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.30200100414043224\n",
      "val: 0.2922280543258729\n",
      "\n",
      "-3.5753e-02\n",
      "-1.2143e-01\n",
      "-7.7582e-02\n",
      "     ⋮      \n",
      " 4.3955e-01\n",
      " 4.3921e-02\n",
      " 3.9677e-02\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.2731683632021344\n",
      "val: 0.2699788908076739\n",
      "\n",
      " 4.9113e-02\n",
      "-1.2379e-01\n",
      "-6.7401e-02\n",
      "     ⋮      \n",
      " 4.0749e-01\n",
      " 4.4266e-02\n",
      " 3.9710e-02\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.2564458419047497\n",
      "val: 0.25638012865284926\n",
      "\n",
      " 0.1079\n",
      "-0.1255\n",
      "-0.0590\n",
      "   ⋮    \n",
      " 0.3894\n",
      " 0.0443\n",
      " 0.0388\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.2461138914724232\n",
      "val: 0.24756394228595083\n",
      "\n",
      " 0.1485\n",
      "-0.1268\n",
      "-0.0521\n",
      "   ⋮    \n",
      " 0.3787\n",
      " 0.0442\n",
      " 0.0379\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.23934979549600732\n",
      "val: 0.24154558453537417\n",
      "\n",
      " 0.1766\n",
      "-0.1278\n",
      "-0.0463\n",
      "   ⋮    \n",
      " 0.3719\n",
      " 0.0441\n",
      " 0.0370\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.23469415366759333\n",
      "val: 0.23725497408428897\n",
      "\n",
      " 0.1960\n",
      "-0.1285\n",
      "-0.0414\n",
      "   ⋮    \n",
      " 0.3674\n",
      " 0.0440\n",
      " 0.0363\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.23135296172772027\n",
      "val: 0.2340849268921141\n",
      "\n",
      " 0.2094\n",
      "-0.1291\n",
      "-0.0373\n",
      "   ⋮    \n",
      " 0.3644\n",
      " 0.0439\n",
      " 0.0358\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.22887136767518132\n",
      "val: 0.23167342922080286\n",
      "\n",
      " 0.2186\n",
      "-0.1295\n",
      "-0.0338\n",
      "   ⋮    \n",
      " 0.3622\n",
      " 0.0437\n",
      " 0.0354\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.22697568801652768\n",
      "val: 0.2297945285921409\n",
      "\n",
      " 0.2249\n",
      "-0.1299\n",
      "-0.0309\n",
      "   ⋮    \n",
      " 0.3606\n",
      " 0.0436\n",
      " 0.0351\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.22549369721231283\n",
      "val: 0.22830129905088792\n",
      "\n",
      " 0.2293\n",
      "-0.1302\n",
      "-0.0283\n",
      "   ⋮    \n",
      " 0.3594\n",
      " 0.0435\n",
      " 0.0349\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "train: 0.22431261080261272\n",
      "val: 0.22709471281979957\n",
      "\n",
      " 0.2322\n",
      "-0.1304\n",
      "-0.0262\n",
      "   ⋮    \n",
      " 0.3585\n",
      " 0.0433\n",
      " 0.0348\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-4b4b9ac8a0fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muser_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-c27a183c819d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, val_iter, test_iter, model)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-c27a183c819d>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1952\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_index_sliceable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_slice\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slobj, axis, kind)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \"\"\"\n\u001b[1;32m   1748\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   3398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3399\u001b[0m         bm = self.__class__(new_blocks, new_axes, do_integrity_check=False,\n\u001b[0;32m-> 3400\u001b[0;31m                             fastpath=True)\n\u001b[0m\u001b[1;32m   3401\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   2797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0mnew_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gaps in blk ref_locs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df, validate_df, test_df = split(testframe)\n",
    "users = len(train_df.uid.unique())\n",
    "tasks = len(train_df.task_id.unique())\n",
    "model = Model(users, tasks, k=2)\n",
    "user_vec, user_bias = train(train_df, validate_df, test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_vec, user_bias = model.user_lut.weight.data, model.user_bias.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = np.zeros((user_vec.numpy().shape[0], user_vec.numpy().shape[1]+1))\n",
    "user_features[:, :user_vec.numpy().shape[1]] = user_vec.numpy()\n",
    "user_features[:, -1] = user_bias.numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.009719  ,  0.02720528,  0.23188628],\n",
       "       [ 0.01690728,  0.01131544, -0.13132867],\n",
       "       [-0.00471632,  0.29508391, -0.0234391 ],\n",
       "       ..., \n",
       "       [ 0.04584001,  0.00829574,  0.35903695],\n",
       "       [ 0.0071434 ,  0.00954419,  0.0429173 ],\n",
       "       [ 0.0468646 ,  0.00940172,  0.02431819]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,     51],\n",
       "       [     1,     52],\n",
       "       [     2,     63],\n",
       "       ..., \n",
       "       [   997, 124421],\n",
       "       [   998, 124432],\n",
       "       [   999, 124439]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt(testframe[['uid','user_id']].drop_duplicates().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150 113 159  51  99  60  60 135  60  98 195 185  60 121 101  60 147 110\n",
      "   8   9  96   7  60 195  60 144 185 164  83 121  98 113  23 172 184 126\n",
      " 197 132  92  77  29 131  77   0 158  66 104  60 167  51   9 110 197 121\n",
      "  60 189   8  19  92 142 164   7  68  60  60  30 164 163  90  71 168  34\n",
      "  57   7  60  60  60  92 154 184 184 126  60 105   9 126  60  34 189  94\n",
      " 155 189  60  68   9  11  60  60 113  60 126  46   9   9 160 172  83 150\n",
      "  70 144  60 162  68 173 110 100 104  47   8 175  60 171  68  38 104  60\n",
      " 164 131 161   9 158  51 126  68 195 146 168 172 106 188 110  60   6 126\n",
      "  60 191   9  97  77 164 173 176  60  60  64 121  51  51 184  60  92   9\n",
      "   1   0 180  60 184  68  21 173   9 113   8 154  81 164 164 104 131   9\n",
      "   9 126 173 182  60 185 103  81 126 126  77 184 121   9 165  90  94 126\n",
      " 199 104  23 154  50   8  70 189  99 117  60 156  43 131  84 157  60 189\n",
      "  79 143  92   8 113 126 121  47 114  95 166  73 131   0 106   7  60   9\n",
      "  68 172  83 197  68   0  78  92 171  34 121 172 159  62 172  98  51  29\n",
      "   7 144  68  37  78 110 105   9 195   9 110 189 118  29 126 171  68   0\n",
      " 113  51 158  88 140 102 171 154 171 171 168 131 184 131  92 168 121  40\n",
      " 129  35 181  68 188 121 189   9 108  92 197  92  23 113 113  68 177  68\n",
      " 189 176  40 172 156 184  83  92 115 172 156 164  92 184 185  90 123 116\n",
      "   7 184  30  29  68 164 185 155 197  29   7 189  29   7   0 191 171  98\n",
      "  71 188 121   9   7 142  41 158 160 167 197 113 144  40 191  52 151   7\n",
      "  55  57 153  13  92  95  66 195 166 184 126   9 126 114 168  90 140 127\n",
      " 180  92 184 109 146  34 126 172 138  92  98 113 171  50  13 164  56  45\n",
      "   8 172 168 148 153   8 137 166 172 111 126 189  29  68 102  99 144 171\n",
      "  85 171  37 126 155 124  60   9 171 167 132 104 154 168  60  13  68 197\n",
      " 110 171  29  29 172  24   0   9 171 166 184 104 191  87   0  60 152 144\n",
      " 126  29 144  92  99 172 146  35 186  60  69  83  99  90 194  99 111  92\n",
      "   7   0  37  71  27 113 126   0 195   7  99  40   0  29 126 166 195  99\n",
      "  40   9  99   7 108  68  50   7  20 188 189 172  60  98 121 171  40 165\n",
      " 170 140 142  68 195  51  57  23 113 189 126 197 110  68  85 102 171 164\n",
      " 195 189 185  68   0 190  92  90  23 197 171 168  68 102 137  23  98  92\n",
      "   9  92  40 121 191  42 164 172 164 177 120 193 164  98 164 191   0 195\n",
      "  10  77   7 193 189 177 102 109  98   0 195 158   7   7 121   0 188 153\n",
      "   0  40 164 197 171 158  46  68 191  99 150  51 158  92  51  16 164  85\n",
      "  37 110 191  71  46 195 141 158  82 190   0  51  99  76 166  89   0  92\n",
      "  51   6  71   7 165  23 104 110  51 178 144  40 189  57  19 191  40  51\n",
      "  95 177 183 189 151 158 102 144 133 191 188   0 121 104  93  71  98  33\n",
      "  64 196  13  57 126  74 150 185 191  60  40  98 132  76   7 164  54 169\n",
      " 168 158 114 158  65  46 158  60  66 150  58  23 130  97   3 194 198  12\n",
      "  40   7 121 194 102 197 191  86  70  23 134  80 153 113 155  34  98 193\n",
      "  21 121   9  68  68  71  36  68 131  56 131 179  94 121   9 119  42  68\n",
      "  68 109  71 171  40   4 126  29  78  92  29  79 168  14 171  32   9 137\n",
      "   8 158  68  88  13  24  29 195  68  64  92 145 154  29  63 131  68 172\n",
      "  68   2   9 128 192  44 111 172 160 168 184  40 193  70  23   8 186   0\n",
      "  68 107 195  94  68 188  98   0  67  26 188  23   5  18   9 165  49 143\n",
      " 121   9   2 136 193 168 144  68 131 189   6 105  53 144 184 109  51  40\n",
      "  24 155 166  52 172  97 193  40  68  25 121  92 188  83  28 121  91  78\n",
      " 190 185 195 189 121  98  66  92 173 126  92  80 156 185 184 172 164 151\n",
      " 114 187 151 189 126 171 165 166 172 193  29  99 125  53 112 110 126  98\n",
      "  69  28   9 158 164 164  92  72  37   9  56 102 109 171  50  91 113  23\n",
      " 172 193  71 168  75  92 188  12  56 122  68   7  61 106  81   9  29 184\n",
      " 144  51  31   0 193  46 153 121  29  17 131   5  95 195  40 140 110 117\n",
      "  40  51 119   7 189  33 153 164   7 191  69  40 149  78 158 171 164  98\n",
      "  48 188 158 197 174 151 139 144 164  22  87  46 116 151 193  51 184 195\n",
      "  39 168 144 171 185   9   0  29  40 197 137 126  19  92  79  21  23 110\n",
      "  68 195  15 155  29   7 150  29  40   7 188 171 191   9   7 166   7  39\n",
      " 193  23  59 158  92 189  46  46 188  92]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=200, random_state=0).fit(user_features)\n",
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "completed, values, ind = compute_individual_dist(mini_tf, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "127.64959692955017\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "features = np.empty((ind.shape[0], ind.shape[1]**2*ind.shape[0]))\n",
    "delta_matrices_all = np.empty((ind.shape[0], ind.shape[0], ind.shape[1], ind.shape[1]))\n",
    "score_matrices_all = np.empty((ind.shape[0], ind.shape[0], ind.shape[1], ind.shape[1]))\n",
    "for user_index in range(values.shape[0]):\n",
    "    if user_index%100==0:\n",
    "        print(user_index)\n",
    "    #check for full joint distribution or add a prior later\n",
    "    if np.sum(ind[user_index]==0) > 0:\n",
    "        continue\n",
    "    #compute delta matrices with all other users where applicable\n",
    "    else:\n",
    "        #create a mask so that other half of tasks can be used later to find score matrix\n",
    "#         mask = np.random.randint(0,2,values.shape).astype(bool)\n",
    "        mask = np.ones((values.shape)).astype(bool)\n",
    "        delta_matrices, t_m_i_1, cluster_img = compute_deltas(user_index, completed, values, ind, mask, False, 20)\n",
    "        features[user_index,:] = cluster_img.flatten()\n",
    "        delta_matrices_all[user_index,:,:,:] = delta_matrices\n",
    "#         score_matrices, t_m_i_2 = compute_deltas(user_index, completed, values, ind, ~mask, True, 20)\n",
    "#         score_matrices_all[user_index,:,:,:] = score_matrices\n",
    "#         print(np.sum(t_m_i_1), np.sum(t_m_i_2))\n",
    "#         if len(np.intersect1d(np.array(np.where(t_m_i_1==True)), np.array(np.where(t_m_i_2==True))))>0:\n",
    "#             print(np.intersect1d(np.array(np.where(t_m_i_1==True)), np.array(np.where(t_m_i_2==True))))\n",
    "#             print(regret(score_matrices, delta_matrices, \\\n",
    "#                      np.logical_and((t_m_i_1==True), (t_m_i_2==True))))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110825"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_missing(X, n_clusters, max_iter=10):\n",
    "    \"\"\"Perform K-Means clustering on data with missing values.\n",
    "\n",
    "    Args:\n",
    "      X: An [n_samples, n_features] array of data to cluster.\n",
    "      n_clusters: Number of clusters to form.\n",
    "      max_iter: Maximum number of EM iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "      labels: An [n_samples] vector of integer labels.\n",
    "      centroids: An [n_clusters, n_features] array of cluster centroids.\n",
    "      X_hat: Copy of X with the missing values filled in.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize missing values to their column means\n",
    "    missing = ~np.isfinite(X)\n",
    "    mu = np.nanmean(X, 0, keepdims=1)\n",
    "    X_hat = np.where(missing, mu, X)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        print(i)\n",
    "        if i > 0:\n",
    "            # initialize KMeans with the previous set of centroids. this is much\n",
    "            # faster and makes it easier to check convergence (since labels\n",
    "            # won't be permuted on every iteration), but might be more prone to\n",
    "            # getting stuck in local minima.\n",
    "            cls = KMeans(n_clusters, init=prev_centroids)\n",
    "        else:\n",
    "            # do multiple random initializations in parallel\n",
    "            cls = KMeans(n_clusters, n_jobs=-1)\n",
    "\n",
    "        # perform clustering on the filled-in data\n",
    "        labels = cls.fit_predict(X_hat)\n",
    "        centroids = cls.cluster_centers_\n",
    "\n",
    "        # fill in the missing values based on their cluster centroids\n",
    "        X_hat[missing] = centroids[labels][missing]\n",
    "\n",
    "        # when the labels have stopped changing then we have converged\n",
    "        if i > 0 and np.all(labels == prev_labels):\n",
    "            break\n",
    "\n",
    "        prev_labels = labels\n",
    "        prev_centroids = cls.cluster_centers_\n",
    "\n",
    "    return labels, centroids, X_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:893: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197  15  25 129   1  15  37  59  15  21  24  24   1  49 161  15   1  88\n",
      " 118 107   1   1  15  46   3   8   6  40  11  55  21 107  37 163  15   1\n",
      " 128 187  49 141  33  87 118 130 163   1 199  15   1  55  15   1  27  96\n",
      " 107  55  95  77  59   1   2  13  31  15  15   1  38 144 135  98  52  59\n",
      " 117  98  15  15  15  17 159  31  15  31  57  52  15  15  57  25  53 118\n",
      "  72  33  15  55  15 184  31 107 107 128   3  73  15  86  15  59   1   1\n",
      "  40  40  15  52 107  53  31  53   3   1   1 140 189  23  53 141 141  15\n",
      "  18  99  39  15  91  59  33 107   1  95  28 113 162  23  53 141  59  31\n",
      "  15  45  31  27  44 130  31  89  57  31  17  11  81  23  31  15  99  31\n",
      " 125   5  22  57 128  11  22  86 107   1   1 124 158  38  12   1   1  15\n",
      " 141  53 141 199  15  42   1   4  15  33   3  15  55  15 134  21  53   3\n",
      " 154 199  59   0  25 193   4  53 130 175  15  53   1  99 106   1  15  37\n",
      "   7  81 113   1 141 107  28 169 128  93  17  36   1   1   1 194  15 141\n",
      "   3  81   1  33  52  81  52  33  55  77  37 118 131  77  55 171  59  81\n",
      "  72 180 107 130  53   1  55   3   1 141 107 107  54  55  55  55  33  81\n",
      "  57   8  79   1 182 190  37  24   3 107  11  59 107  81  17 172  55  59\n",
      " 140   3  31  31  81  52 107  15   1  17  22  95 153   1   3 163   1  33\n",
      "  33 163   9 163 198 199  86 163   1  59  37 163  55  15 113  69 123   1\n",
      "  74   1 181  87  33  81  38  40   3 129 171  33  49 191  28  98  37 105\n",
      "  35 154   1  15  72 181  95  79 116  22  37 141  11  96  39 141  99  70\n",
      "  68   1  99 163  85   3  81  48  81 107 107   1  15  52 163   1 130   1\n",
      "   1 163  31  92 141  53  15   1 186  33 191   1  31   1 113 122  10  67\n",
      "  49 163  55   1  78  99  99 122  81   1 141  33  55   3  53  21 117   3\n",
      "  37  86  24 187 131 184   1  15  11 199  53  22  53  49 107   1  33  86\n",
      " 177   1  37  53   1  97  81 141  17  53   3   1   1   1  99   3   6  81\n",
      " 107 119  38  33  78  59  83   1   1  15   1  53 115 103   1 143  31  99\n",
      "  19  96  42 130 114 141  27  38 163  13   6   2   6  59  53  11  59 130\n",
      "   1  15  19 150   1   6 154 194 133  81  11  17   1 194  86  15 103  49\n",
      "   4  75 181  57  37   9  55 157  57  33   3 199  88  52  22  86  37  12\n",
      "  93  25  42  53 130  59  81 110  31   1 148  99  37  95  49   4   1   6\n",
      "  57  99 121  93  51 118  12  99  82 115   1 105  42   1   2  78  81   6\n",
      "  24   1   2 115  85  74 157  88  14  96 113  81  42  14 113  38  17  51\n",
      "  33  17  12  86  17 130  73  33 150 168   2   8  91   7   1  17   1  66\n",
      "  17  57  78  21  78  17  39  12 141   1  32  49 130 195  99   1 122  59\n",
      " 163   1   6  78  24 118 107  86  55  74  28  12 149  89 116   1  17  55\n",
      "   1  73  60  31  26   6 127 105  73  42   9 190  33  66  63  35  12   1\n",
      "  50  57   1  59  93 136 191 147  70   1 103 126   1 142 194  12   1  85\n",
      "  89   8  25  17 140  76   1 141 102  70  40 154  52 116 138  19 163  12\n",
      " 113 174  55  32 118  66 130  30  99  66   1  16  58  27  78  55  18  12\n",
      "  77  37  37 129  55  79 152 127 188  55  11  27   1  33 107 179  16  37\n",
      " 107   1  79  33  21  84 107 190 120  59 157   4 117   1  55  10  31 154\n",
      " 192   5  15   1  56  27  49  17   1   1  26   1  59  52   1   7 107  11\n",
      " 141 122   3 183 173 184  36  49  87 118  95 113   1 113  37  86  77   5\n",
      "  86 100 101  37  52  52  21   9  80 101 113  55 182   1  27 155   1 184\n",
      "  33  95  37   1  79 163  81   3  79   1 167   1 165  28 129  77  33  42\n",
      "  53  78 105  22  55  88  12 162  37 151  37  11  81 118  65  53 199   0\n",
      " 122   4 163  33  49 176   1  81  57   1  55  37   1  81  31  37  40 160\n",
      "  37  77  62  86   3  55 101  96  99 103  37   1  27  41   1  66  33 137\n",
      " 164  77 141   1 139  34  55  50  60  15  27  31 128  33 118  53   3  61\n",
      " 163  19 113   9  28  81   1   1  10  22  52  19  46   8 170  57 113  88\n",
      " 105  20   1  96 190  64   9  47  37   1   1   7 148  81 121 108 145   1\n",
      "  61  20  75  73  37   1 166 178  94 103 104  72  90  37 163  57  35  78\n",
      "   1  99 130  95   1 111  95  21   1   1 156   1 154   8  72   6 107   5\n",
      "  43 185  59 157 121  55  71  55  21   1   1  53 183  24  35   1  69 107\n",
      "   6 113   1 109 163  42  76 163 112  19  17  52   1   1 150  21 171 196\n",
      "  17  86 146  38   8  33 132  29  28 163]\n"
     ]
    }
   ],
   "source": [
    "labels, centroids, X_hat = kmeans_missing(features, 200, max_iter=5)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cluster_matrix_dist(labels, delta_matrices_all):\n",
    "#     delta_matrices_new=np.zeros((len(np.unique(labels)), len(np.unique(labels)), delta_matrices_all[0][0].shape[0], \\\n",
    "#                                                               delta_matrices_all[0][0].shape[1]))\n",
    "    delta_matrices_new=np.empty(delta_matrices_all.shape)\n",
    "    for i in np.unique(labels):\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        missing = ~np.isfinite(delta_matrices_all)\n",
    "        mu = np.nanmean(delta_matrices_all, 0, keepdims=0)\n",
    "        filled = np.where(missing, mu, delta_matrices_all)\n",
    "        cluster_i = np.average(filled[labels==i], axis=0)\n",
    "        for j in np.unique(labels): \n",
    "            if np.sum(np.sum(np.isnan(cluster_i), (1,2)))>0:\n",
    "                print(i,j)\n",
    "                missing = ~np.isfinite(deltas_used)\n",
    "                mu = np.nanmean(delta_matrices_all, 1, keepdims=1)\n",
    "                X_hat = np.where(missing, mu, X)\n",
    "            cluster_j = np.average(cluster_i[labels==j], axis=0)\n",
    "#             delta_matrices_new[i,j] = cluster_j\n",
    "            delta_matrices_new[np.ix_(labels==i,labels==j)] = cluster_j\n",
    "    return delta_matrices_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "delta_matrices_clust = calc_cluster_matrix_dist(labels, delta_matrices_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0776220916645\n"
     ]
    }
   ],
   "source": [
    "print(np.average([[pairwise_distances(score_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "0.0770279382517\n"
     ]
    }
   ],
   "source": [
    "delta_matrices_clust = calc_cluster_matrix_dist(kmeans.labels_, delta_matrices_all)\n",
    "print(np.average([[pairwise_distances(delta_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: 2.0534805581363393\n",
      "train: 0.6785000668071375\n",
      "val: 0.27297596169423294\n",
      "train: 0.2455079876871621\n",
      "val: 0.23177292823756387\n",
      "train: 0.2265714453881669\n",
      "val: 0.22370148841727236\n",
      "train: 0.22186856493315193\n",
      "val: 0.2209202693637123\n",
      "train: 0.22004835924754415\n",
      "val: 0.21966143299615062\n",
      "train: 0.219158649219987\n",
      "val: 0.21898384552321554\n",
      "train: 0.21865170748941362\n",
      "val: 0.21857142395474966\n",
      "train: 0.21832812664990076\n",
      "val: 0.2182944864299073\n",
      "train: 0.21810089579953965\n",
      "val: 0.2180912764652227\n",
      "train: 0.21792648978623758\n",
      "val: 0.21792872818239606\n",
      "train: 0.21778057300708967\n",
      "val: 0.2177872638569634\n",
      "train: 0.2176481001638066\n",
      "val: 0.21765412888569582\n",
      "train: 0.21751879636900456\n",
      "val: 0.21752017037388582\n",
      "train: 0.21738491183119227\n",
      "val: 0.2173781772053228\n",
      "train: 0.217240045089088\n",
      "val: 0.21722199753704172\n",
      "train: 0.2170785347842071\n",
      "val: 0.21704611106295554\n",
      "train: 0.21689519295379342\n",
      "val: 0.21684547640761825\n",
      "train: 0.2166852778300971\n",
      "val: 0.21661560282260073\n",
      "train: 0.2164446498244093\n",
      "val: 0.21635278058664725\n",
      "train: 0.21617005482689966\n",
      "val: 0.21605440781159388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:248: RuntimeWarning: invalid value encountered in add\n",
      "  distances += XX\n",
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:400: RuntimeWarning: overflow encountered in square\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:400: RuntimeWarning: invalid value encountered in subtract\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:401: RuntimeWarning: overflow encountered in square\n",
      "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "K=2 score: 0.07221198567612774\n",
      "val: 2.2423194358614276\n",
      "train: 0.7294973150204543\n",
      "val: 0.2832449913020912\n",
      "train: 0.25099779028384644\n",
      "val: 0.2343993986418496\n",
      "train: 0.22830796611023044\n",
      "val: 0.22490978366595735\n",
      "train: 0.2227166322422639\n",
      "val: 0.22167280479301246\n",
      "train: 0.22056278936072474\n",
      "val: 0.22021889376343023\n",
      "train: 0.21951830141534204\n",
      "val: 0.21944693638237456\n",
      "train: 0.21893284925849563\n",
      "val: 0.21898784123147727\n",
      "train: 0.218569648081213\n",
      "val: 0.21869085675493266\n",
      "train: 0.2183261693932684\n",
      "val: 0.21848535396232144\n",
      "train: 0.21815222703885986\n",
      "val: 0.21833473423500593\n",
      "train: 0.2180208749890265\n",
      "val: 0.21821847143287273\n",
      "train: 0.21791652644402623\n",
      "val: 0.21812426964257983\n",
      "train: 0.21782956036958445\n",
      "val: 0.2180443033035051\n",
      "train: 0.2177536631414168\n",
      "val: 0.21797327939565111\n",
      "train: 0.2176844234318902\n",
      "val: 0.2179073832868934\n",
      "train: 0.21761853896283134\n",
      "val: 0.2178436504149933\n",
      "train: 0.21755334623548458\n",
      "val: 0.21777960052437015\n",
      "train: 0.2174865205487035\n",
      "val: 0.2177129811916402\n",
      "train: 0.21741587649367722\n",
      "val: 0.21764159719619117\n",
      "train: 0.2173392284564552\n",
      "val: 0.21756319673046462\n",
      "0\n",
      "100\n",
      "K=3 score: 0.07696240209904044\n",
      "val: 2.471580696576524\n",
      "train: 0.7945727522588686\n",
      "val: 0.3084626799783359\n",
      "train: 0.26707777250676495\n",
      "val: 0.2448238577183559\n",
      "train: 0.23550205403951058\n",
      "val: 0.23027559833777608\n",
      "train: 0.22661954263894968\n",
      "val: 0.22486215351607697\n",
      "train: 0.22291350759060266\n",
      "val: 0.22226556282671547\n",
      "train: 0.2209953443388367\n",
      "val: 0.2207954321334401\n",
      "train: 0.21984789822889514\n",
      "val: 0.21985601007794484\n",
      "train: 0.21908159064916738\n",
      "val: 0.21919413306010987\n",
      "train: 0.21851978384013937\n",
      "val: 0.2186859381735127\n",
      "train: 0.2180713359070508\n",
      "val: 0.21826343093708653\n",
      "train: 0.2176838335683259\n",
      "val: 0.21788528219832615\n",
      "train: 0.21732402599999082\n",
      "val: 0.21752387877261262\n",
      "train: 0.21696882051391256\n",
      "val: 0.21715911397482393\n",
      "train: 0.2166009136009783\n",
      "val: 0.21677535317229174\n",
      "train: 0.21620670779040377\n",
      "val: 0.21636006002979702\n",
      "train: 0.21577549249026415\n",
      "val: 0.2159034098224138\n",
      "train: 0.2152993781230994\n",
      "val: 0.21539850303332458\n",
      "train: 0.21477364068103047\n",
      "val: 0.21484188390829986\n",
      "train: 0.21419716017847862\n",
      "val: 0.21423399965558895\n",
      "train: 0.21357263253092068\n",
      "val: 0.2135793375765773\n",
      "0\n",
      "100\n",
      "K=4 score: 0.07696868339571307\n",
      "val: 2.655668926575656\n",
      "train: 0.8457770355554328\n",
      "val: 0.3228170884569195\n",
      "train: 0.2758690029077328\n",
      "val: 0.25085392864412287\n",
      "train: 0.2393310055102421\n",
      "val: 0.23352813458577953\n",
      "train: 0.22865346492803618\n",
      "val: 0.22685608879520072\n",
      "train: 0.2241119997623818\n",
      "val: 0.22358463120626948\n",
      "train: 0.2217415543030912\n",
      "val: 0.22170934470399853\n",
      "train: 0.22032057367669153\n",
      "val: 0.22050369786019122\n",
      "train: 0.21937212310778814\n",
      "val: 0.21965156654561913\n",
      "train: 0.2186770101764265\n",
      "val: 0.21899543468147956\n",
      "train: 0.21812118880199877\n",
      "val: 0.21844783046793884\n",
      "train: 0.21763890026184782\n",
      "val: 0.21795548007702706\n",
      "train: 0.21718872623407376\n",
      "val: 0.21748332460934783\n",
      "train: 0.21674268296264157\n",
      "val: 0.2170070275043744\n",
      "train: 0.21628112894216142\n",
      "val: 0.21650948470587966\n",
      "train: 0.21579048938575063\n",
      "val: 0.21597931706627266\n",
      "train: 0.21526233981741744\n",
      "val: 0.21541026249977405\n",
      "train: 0.2146929954429361\n",
      "val: 0.21480077011845186\n",
      "train: 0.21408303518981228\n",
      "val: 0.2141533079303472\n",
      "train: 0.21343647920820868\n",
      "val: 0.21347332105887415\n",
      "train: 0.2127596230554802\n",
      "val: 0.21276793960860804\n",
      "0\n",
      "100\n",
      "K=5 score: 0.07689499842165001\n",
      "val: 2.9005566862723726\n",
      "train: 0.8965242496940368\n",
      "val: 0.3312249376090038\n",
      "train: 0.28124381434779533\n",
      "val: 0.2533743508384759\n",
      "train: 0.2410021181427805\n",
      "val: 0.23450711657943601\n",
      "train: 0.22924294648127394\n",
      "val: 0.22726112456247222\n",
      "train: 0.2242732950875047\n",
      "val: 0.22372010043998705\n",
      "train: 0.2216967189786885\n",
      "val: 0.22170088574343508\n",
      "train: 0.2201647862921241\n",
      "val: 0.2204132779565037\n",
      "train: 0.21915286224820216\n",
      "val: 0.21951364956191874\n",
      "train: 0.21842049449711146\n",
      "val: 0.21883085874753036\n",
      "train: 0.2178429242739261\n",
      "val: 0.21826987380239063\n",
      "train: 0.21734838792848213\n",
      "val: 0.21777272459491714\n",
      "train: 0.21689168084211682\n",
      "val: 0.21730104440703446\n",
      "train: 0.2164420901115205\n",
      "val: 0.2168278709255999\n",
      "train: 0.21597777513279082\n",
      "val: 0.21633388800821762\n",
      "train: 0.21548336745388513\n",
      "val: 0.21580599138790058\n",
      "train: 0.21494922519307488\n",
      "val: 0.215236974224588\n",
      "train: 0.21437134800247276\n",
      "val: 0.2146254523702321\n",
      "train: 0.21375116557431795\n",
      "val: 0.2139753149404913\n",
      "train: 0.21309467347383693\n",
      "val: 0.2132943798237283\n",
      "train: 0.21241081390842545\n",
      "val: 0.21259244544091194\n",
      "0\n",
      "100\n",
      "K=6 score: 0.07673734503641744\n",
      "val: 3.0643913474049342\n",
      "train: 0.9394557891163562\n",
      "val: 0.34084833774250306\n",
      "train: 0.2859678505442869\n",
      "val: 0.2567814742571955\n",
      "train: 0.2429070650734224\n",
      "val: 0.23633439429476713\n",
      "train: 0.23034194195158947\n",
      "val: 0.2284779289629335\n",
      "train: 0.22501526266758357\n",
      "val: 0.22463574034898953\n",
      "train: 0.22225021624081506\n",
      "val: 0.2224506852853757\n",
      "train: 0.2206136300208845\n",
      "val: 0.22106879965135354\n",
      "train: 0.2195465031411077\n",
      "val: 0.2201191363372226\n",
      "train: 0.21879319086890056\n",
      "val: 0.2194187287883769\n",
      "train: 0.2182227477124957\n",
      "val: 0.21886832117750107\n",
      "train: 0.21776197687659712\n",
      "val: 0.21840975596816714\n",
      "train: 0.2173668797473851\n",
      "val: 0.21800664149819457\n",
      "train: 0.21700925678786642\n",
      "val: 0.21763480381532566\n",
      "train: 0.2166699534207736\n",
      "val: 0.21727731247265836\n",
      "train: 0.2163352745280952\n",
      "val: 0.21692175949653006\n",
      "train: 0.21599501583138603\n",
      "val: 0.21655875201424762\n",
      "train: 0.21564136932945485\n",
      "val: 0.21618105679255317\n",
      "train: 0.21526832629856482\n",
      "val: 0.21578314307001556\n",
      "train: 0.21487135895829781\n",
      "val: 0.21536094243669165\n",
      "train: 0.2144472633876542\n",
      "val: 0.2149117064726254\n",
      "0\n",
      "100\n",
      "K=7 score: 0.07703610198662506\n",
      "val: 3.1600097860787657\n",
      "train: 0.9766401905093365\n",
      "val: 0.3516314774359778\n",
      "train: 0.29347898272098405\n",
      "val: 0.2614658573016085\n",
      "train: 0.24620808210825912\n",
      "val: 0.23854326958285\n",
      "train: 0.23188257039935806\n",
      "val: 0.22954551925490177\n",
      "train: 0.22571740045415986\n",
      "val: 0.22510521194251804\n",
      "train: 0.22248832910143101\n",
      "val: 0.22254997564864581\n",
      "train: 0.22054710660151858\n",
      "val: 0.2208957139253184\n",
      "train: 0.2192431833962995\n",
      "val: 0.21971266040733967\n",
      "train: 0.218277326069996\n",
      "val: 0.21878789614720265\n",
      "train: 0.2174951480804691\n",
      "val: 0.21800504588296496\n",
      "train: 0.2168095874453252\n",
      "val: 0.2172955486264711\n",
      "train: 0.21616834619142927\n",
      "val: 0.21661713122650994\n",
      "train: 0.21553916623113137\n",
      "val: 0.21594372027487183\n",
      "train: 0.21490279810205906\n",
      "val: 0.21526044461754254\n",
      "train: 0.21424933664970652\n",
      "val: 0.21456075664276303\n",
      "train: 0.21357583563407553\n",
      "val: 0.21384425060383225\n",
      "train: 0.2128842418909866\n",
      "val: 0.21311453910571482\n",
      "train: 0.2121793713170051\n",
      "val: 0.21237724120646115\n",
      "train: 0.21146709931350677\n",
      "val: 0.2116383091524762\n",
      "train: 0.21075304538538456\n",
      "val: 0.21090297148729834\n",
      "0\n",
      "100\n",
      "K=8 score: 0.07711343282321603\n",
      "val: 3.2958979506704034\n",
      "train: 1.0130181041266861\n",
      "val: 0.3623177266646639\n",
      "train: 0.3003939605803883\n",
      "val: 0.2654544805239922\n",
      "train: 0.2492975262939059\n",
      "val: 0.24075417433555754\n",
      "train: 0.23378282124934288\n",
      "val: 0.23104251032892656\n",
      "train: 0.22708227670899797\n",
      "val: 0.22624068322187604\n",
      "train: 0.22356119791175577\n",
      "val: 0.22348454552552643\n",
      "train: 0.2214474755762303\n",
      "val: 0.22171805308391362\n",
      "train: 0.22003980258919917\n",
      "val: 0.2204765877205623\n",
      "train: 0.21901258323313533\n",
      "val: 0.2195267577096755\n",
      "train: 0.218194818657078\n",
      "val: 0.2187378692243446\n",
      "train: 0.2174868869484555\n",
      "val: 0.2180295121433059\n",
      "train: 0.21682539401004683\n",
      "val: 0.21734832900589893\n",
      "train: 0.21616745293735037\n",
      "val: 0.21665755998065903\n",
      "train: 0.21548388738259402\n",
      "val: 0.215932840856963\n",
      "train: 0.21475683015281738\n",
      "val: 0.21516101314970834\n",
      "train: 0.2139791698373222\n",
      "val: 0.21433978565984657\n",
      "train: 0.21315394438913782\n",
      "val: 0.21347658016409335\n",
      "train: 0.21229240573859468\n",
      "val: 0.21258571090943304\n",
      "train: 0.21141056075057163\n",
      "val: 0.21168435222234488\n",
      "train: 0.21052516012537043\n",
      "val: 0.21078867371706653\n",
      "0\n",
      "100\n",
      "K=9 score: 0.077089891932015\n",
      "val: 3.423229384031401\n",
      "train: 1.0518755762099308\n",
      "val: 0.37407299650777687\n",
      "train: 0.3068732113455731\n",
      "val: 0.2697436385988344\n",
      "train: 0.25169771274239605\n",
      "val: 0.24251474346413554\n",
      "train: 0.23472296246645122\n",
      "val: 0.23180161749188705\n",
      "train: 0.2274123037280554\n",
      "val: 0.22653169962853878\n",
      "train: 0.2235874083393066\n",
      "val: 0.2235152080365319\n",
      "train: 0.2212892778803317\n",
      "val: 0.22157675490659373\n",
      "train: 0.21974557687662952\n",
      "val: 0.2202026793416819\n",
      "train: 0.21860103591953484\n",
      "val: 0.21913715632650385\n",
      "train: 0.21767128769558697\n",
      "val: 0.21823852982716122\n",
      "train: 0.21685083913154396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: 0.21742152916623586\n",
      "train: 0.21607492035705536\n",
      "val: 0.2166321971710068\n",
      "train: 0.2153028708368665\n",
      "val: 0.21583684073262258\n",
      "train: 0.21451089335468704\n",
      "val: 0.21501712797898398\n",
      "train: 0.21368868294836912\n",
      "val: 0.21416744601214494\n",
      "train: 0.2128369059744627\n",
      "val: 0.21329213870246314\n",
      "train: 0.21196399854017556\n",
      "val: 0.21240182665205143\n",
      "train: 0.2110821958812203\n",
      "val: 0.21150927523559532\n",
      "train: 0.21020378769678388\n",
      "val: 0.21062607806430914\n",
      "train: 0.20933873165707428\n",
      "val: 0.20976095250539348\n",
      "0\n",
      "100\n",
      "K=10 score: 0.07700706690149926\n"
     ]
    }
   ],
   "source": [
    "for k_ in range(2,11):\n",
    "    model = Model(users, tasks, k=k_)\n",
    "    user_vec, user_bias = train(train_df, validate_df, test_df, model)\n",
    "    user_features = np.empty((user_vec.numpy().shape[0], user_vec.numpy().shape[1]+1))\n",
    "    user_features[:, :user_vec.numpy().shape[1]] = user_vec.numpy()\n",
    "    user_features[:, :-1] = user_bias.numpy()\n",
    "    kmeans = KMeans(n_clusters=200, random_state=0).fit(user_features)\n",
    "    delta_matrices_clust = calc_cluster_matrix_dist(kmeans.labels_, delta_matrices_all)\n",
    "    avg_dist = np.average([[pairwise_distances(delta_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)])\n",
    "    max_dist = np.max([[pairwise_distances(delta_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)])\n",
    "    print(\"K={} score: {}, {}\".format(k_, avg_dist, max_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(user_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:248: RuntimeWarning: invalid value encountered in add\n",
      "  distances += XX\n",
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:400: RuntimeWarning: overflow encountered in square\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:400: RuntimeWarning: invalid value encountered in subtract\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:401: RuntimeWarning: overflow encountered in square\n",
      "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "K=2 score: 0.07221198567612774, 0.7124813399972646\n"
     ]
    }
   ],
   "source": [
    "# for k_ in range(2,3):\n",
    "#     model = Model(users, tasks, k=k_)\n",
    "#     user_vec, user_bias = train(train_df, validate_df, test_df, model)\n",
    "#     user_features = np.empty((user_vec.numpy().shape[0], user_vec.numpy().shape[1]+1))\n",
    "#     user_features[:, :user_vec.numpy().shape[1]] = user_vec.numpy()\n",
    "#     user_features[:, :-1] = user_bias.numpy()\n",
    "sc = KMeans(n_clusters=200, random_state=0).fit(user_features)\n",
    "delta_matrices_clust = calc_cluster_matrix_dist(sc.labels_, delta_matrices_all)\n",
    "avg_dist = np.average([[pairwise_distances(delta_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)])\n",
    "max_dist = np.max([[pairwise_distances(delta_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)])\n",
    "print(\"K={} score: {}, {}\".format(k_, avg_dist, max_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "K=2 score: 0.07887018199302073\n"
     ]
    }
   ],
   "source": [
    "kmeans = AffinityPropagation().fit(user_features)\n",
    "delta_matrices_clust = calc_cluster_matrix_dist(kmeans.labels_, delta_matrices_all)\n",
    "avg_dist = np.average([[pairwise_distances(delta_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)])\n",
    "print(\"K={} score: {}\".format(k_, avg_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
