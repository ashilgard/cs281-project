{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from itertools import combinations_with_replacement\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering, AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gj = pd.read_csv('./filled_active_df.csv')\n",
    "gj = gj[['ifp_id', 'ctt', 'cond', 'training', 'team', 'user_id', 'value', 'fcast_date']]\n",
    "gj['fcast_year'] = pd.to_datetime(gj['fcast_date']).dt.year\n",
    "gj['fcast_week'] = pd.to_datetime(gj['fcast_date']).dt.week\n",
    "gj['ifp_week'] = gj['fcast_year'].map(str) + gj['fcast_week'].map(str) + gj['ifp_id']\n",
    "gj = gj.drop('fcast_date', axis=1)\n",
    "gj = gj.drop_duplicates()\n",
    "gj.to_csv('./gj_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ifp_id</th>\n",
       "      <th>ctt</th>\n",
       "      <th>cond</th>\n",
       "      <th>training</th>\n",
       "      <th>team</th>\n",
       "      <th>user_id</th>\n",
       "      <th>value</th>\n",
       "      <th>fcast_date</th>\n",
       "      <th>fcast_year</th>\n",
       "      <th>fcast_week</th>\n",
       "      <th>ifp_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-24</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ifp_id ctt  cond training  team  user_id  value  fcast_date  fcast_year  \\\n",
       "0  1244-0  1a     1        a   NaN       51    0.2  2015-01-15        2015   \n",
       "1  1244-0  1a     1        a   NaN       51    0.2  2015-01-16        2015   \n",
       "2  1244-0  1a     1        a   NaN       51    0.2  2015-01-17        2015   \n",
       "3  1244-0  1a     1        a   NaN       51    0.2  2015-01-18        2015   \n",
       "4  1244-0  1a     1        a   NaN       51    0.2  2015-01-19        2015   \n",
       "5  1244-0  1a     1        a   NaN       51    0.2  2015-01-20        2015   \n",
       "6  1244-0  1a     1        a   NaN       51    0.2  2015-01-21        2015   \n",
       "7  1244-0  1a     1        a   NaN       51    0.2  2015-01-22        2015   \n",
       "8  1244-0  1a     1        a   NaN       51    0.2  2015-01-23        2015   \n",
       "9  1244-0  1a     1        a   NaN       51    0.2  2015-01-24        2015   \n",
       "\n",
       "   fcast_week     ifp_week  \n",
       "0           3  201531244-0  \n",
       "1           3  201531244-0  \n",
       "2           3  201531244-0  \n",
       "3           3  201531244-0  \n",
       "4           4  201541244-0  \n",
       "5           4  201541244-0  \n",
       "6           4  201541244-0  \n",
       "7           4  201541244-0  \n",
       "8           4  201541244-0  \n",
       "9           4  201541244-0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adult = pd.read_csv('../labels.txt', delimiter='\\t', header=0, names=['user_id','website','rating'])\n",
    "# trec = pd.read_csv('../trec-rf10-crowd/trec-rf10-data.txt', delimiter='\\t')\n",
    "# gj = pd.read_csv('./filled_active_df.csv')\n",
    "\n",
    "# best_users = trec.groupby('workerID').count().sort_values('docID', ascending=False)[:150].index\n",
    "# trec = trec[trec['workerID'].isin(best_users)]\n",
    "\n",
    "# r = pd.Series([2,3,2,3], index=[1,2,0,-2])\n",
    "# trec['label_bin'] = trec['label'].map(r)\n",
    "gj.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ifp_id</th>\n",
       "      <th>ctt</th>\n",
       "      <th>cond</th>\n",
       "      <th>training</th>\n",
       "      <th>team</th>\n",
       "      <th>user_id</th>\n",
       "      <th>value</th>\n",
       "      <th>fcast_date</th>\n",
       "      <th>fcast_year</th>\n",
       "      <th>fcast_week</th>\n",
       "      <th>ifp_week</th>\n",
       "      <th>bin</th>\n",
       "      <th>task_id</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>201531244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244-0</td>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>201541244-0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ifp_id ctt  cond training  team  user_id  value  fcast_date  fcast_year  \\\n",
       "0  1244-0  1a     1        a   NaN       51    0.2  2015-01-15        2015   \n",
       "1  1244-0  1a     1        a   NaN       51    0.2  2015-01-16        2015   \n",
       "2  1244-0  1a     1        a   NaN       51    0.2  2015-01-17        2015   \n",
       "3  1244-0  1a     1        a   NaN       51    0.2  2015-01-18        2015   \n",
       "4  1244-0  1a     1        a   NaN       51    0.2  2015-01-19        2015   \n",
       "\n",
       "   fcast_week     ifp_week  bin  task_id  uid  \n",
       "0           3  201531244-0  0.2        0    0  \n",
       "1           3  201531244-0  0.2        0    0  \n",
       "2           3  201531244-0  0.2        0    0  \n",
       "3           3  201531244-0  0.2        0    0  \n",
       "4           4  201541244-0  0.2        1    0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testframe = create_user_task_ids(adult, 'user_id', 'website', 'rating')\n",
    "testframe = create_user_task_ids(gj, 'user_id', 'ifp_week', 'value', False, True)\n",
    "testframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.cut(\n",
    "    testframe['value'],\n",
    "    [-np.inf, .2, .4, .6, .8, np.inf],\n",
    "    labels=[2,3,5,7,11]\n",
    ")\n",
    "testframe['bin_levels'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_tf = testframe[testframe['uid']<1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def split(df):\n",
    "    train_df, validate_df, test_df = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "    return train_df, validate_df, test_df\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, users, tasks, k=2):\n",
    "        super(Model, self).__init__()\n",
    "        self.user_lut = nn.Embedding(users, k)\n",
    "        self.task_lut = nn.Embedding(tasks, k)\n",
    "\n",
    "        self.user_bias = nn.Embedding(users, 1)\n",
    "        self.task_bias = nn.Embedding(tasks, 1)\n",
    "        self.global_bias = nn.Parameter(torch.FloatTensor(1))\n",
    "        \n",
    "    def forward(self, users, jokes):\n",
    "        user_vectors = self.user_lut(users)\n",
    "        task_vectors = self.task_lut(jokes)\n",
    "        user_bias = self.user_bias(users)\n",
    "        task_bias = self.task_bias(jokes)\n",
    "\n",
    "        return torch.bmm(user_vectors.unsqueeze(1),\n",
    "                         task_vectors.unsqueeze(2)).squeeze() \\\n",
    "                         + user_bias.squeeze() + task_bias.squeeze() + self.global_bias.expand_as(user_bias.squeeze())\n",
    "\n",
    "def val(df, model):\n",
    "    crit = nn.MSELoss(size_average=False)\n",
    "    total_loss = 0.\n",
    "    total_num = 0\n",
    "    for batch in batcher(df, 100):\n",
    "        true_rating = Variable(torch.Tensor(batch.bin.values.astype(float)))\n",
    "        total_num = total_num + true_rating.size(0)\n",
    "        users = Variable(torch.LongTensor(batch.uid.values))\n",
    "        tasks = Variable(torch.LongTensor(batch.task_id.values))\n",
    "        scores = model.forward(users, tasks)\n",
    "        total_loss += crit(scores, true_rating).data[0]\n",
    "    return math.sqrt(total_loss/total_num)\n",
    "\n",
    "\n",
    "def train(train_iter, val_iter, test_iter, model):\n",
    "    opt = optim.SGD(model.parameters(), lr=0.1)\n",
    "    crit = nn.MSELoss()\n",
    "\n",
    "    print(\"val:\", val(validate_df, model))\n",
    "    for epochs in range(10):\n",
    "        avg_loss = 0\n",
    "        total = 0\n",
    "        for i,batch in enumerate(batcher(train_df, 100)):\n",
    "            opt.zero_grad()\n",
    "            rating = Variable(torch.Tensor(batch.bin.values.astype(float)))\n",
    "            users = Variable(torch.LongTensor(batch.uid.values))\n",
    "            tasks = Variable(torch.LongTensor(batch.task_id.values))\n",
    "            scores = model.forward(users, tasks)\n",
    "            loss = crit(scores, rating)\n",
    "            #if i % 1000==0:\n",
    "            #    print (loss.data[0])\n",
    "            loss.backward()\n",
    "            avg_loss += loss.data[0]\n",
    "            total += 1\n",
    "            opt.step()\n",
    "        print(\"train:\", math.sqrt(avg_loss / float(total)))\n",
    "        print(\"val:\", val(validate_df, model))\n",
    "    return model.user_lut.weight.data, model.user_bias.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: 2.021425214664118\n",
      "train: 0.667723291625787\n",
      "val: 0.2707810338877338\n",
      "train: 0.2438547120450365\n",
      "val: 0.23030166764296794\n",
      "train: 0.2255393392086561\n",
      "val: 0.22288885701801994\n",
      "train: 0.22124274013772732\n",
      "val: 0.22046759810117506\n",
      "train: 0.2196418507688387\n",
      "val: 0.21940113176434928\n",
      "train: 0.21887278126535548\n",
      "val: 0.21882969232214922\n",
      "train: 0.21843468186871354\n",
      "val: 0.21847755741050492\n",
      "train: 0.21815149239896467\n",
      "val: 0.21823545003058517\n",
      "train: 0.2179483060409643\n",
      "val: 0.2180525252680432\n",
      "train: 0.21778829251129264\n",
      "val: 0.21790197649609416\n"
     ]
    }
   ],
   "source": [
    "train_df, validate_df, test_df = split(mini_tf)\n",
    "users = len(mini_tf.uid.unique())\n",
    "tasks = len(mini_tf.task_id.unique())\n",
    "model = Model(users, tasks, k=2)\n",
    "user_vec, user_bias = train(train_df, validate_df, test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = np.empty((user_vec.numpy().shape[0], user_vec.numpy().shape[1]+1))\n",
    "user_features[:, :user_vec.numpy().shape[1]] = user_vec.numpy()\n",
    "user_features[:, :-1] = user_bias.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152  67  85 180  11 132 163  25   9 136 145 110  68 144  85  20 123 161\n",
      " 177 118 186  43 124  38 124 146  64  27  18 174  72 195   8 156  30 153\n",
      "  50 153  95  68 138 150  65  58 159  52 199  45 194   8 178 153 108 140\n",
      "  45 107   8  46  29  92 166  39  50 175 124  15  79  75   4 166  59 197\n",
      " 134  21 148 148 194  53 176 112   3   6 124  82 106  46  31   8  41  41\n",
      " 117 140  69 162 178  49 124 163  84  69  30 111  69 142 182 144 119 120\n",
      "  35  10 101 183 153  31 169  12  68  94 156   6 101 157 135  94 148  20\n",
      " 117 198  39  69 143 138  30  50  32 103 122 198  35  81 142 132 160 142\n",
      " 195 137  48  94  50  27 112  64  31 108  88  80   8 126 161  31  40 142\n",
      " 174  81 162   9  65  12 187 124 182  28 169  86  52 191 125  94  96  94\n",
      " 106 163 108  46 132 181 105  98 169  25 161 178  92  31 134 191  92  65\n",
      "  35  69 103  41 176 176 143 119  78 173  67 190  56   4 128  48 116  92\n",
      " 188  62 145 138   9 192 177  65 156 199  29  24  53  58 127 137 182 108\n",
      "  25  40   4  90 183 115   8 126 157  12 107 156  88  87  23  19 177  23\n",
      "   5 122   6  35 176 169  24   3  88 161  90 140 197  82 199 107  86  32\n",
      "  54 126 155 108 122 107 177  61  24 103 115 131 178 149  18 149 107 128\n",
      " 102  41 107  86  29  51  90  46 190 150 192 131 145  54 195  80 165 121\n",
      "  87 125 173  51 193  46 131 197  67 126  82 168 197  31  35 150 151  28\n",
      " 147 190 144   8  12 117   2  11 140  77  72 119   1 133  53  43 135 136\n",
      " 143 134  77  94  21  87 197 128 169 106  12 113  96  17 196 101  98  89\n",
      " 142   4 105  66  53 169 191  38 128 186 130  65  90 193 141  75  11   1\n",
      " 144 189  50  46  65 156   6 102  45  66  78 132 119  66 141  11  77  31\n",
      " 187  61  53  35 137 176  26  64 160 140  31  25  24 157 135 185 159 107\n",
      "  12  92 185  90  85   1 182  46 138 178 161 161  18 115 116 164 130 161\n",
      " 130  92 135  74 102 169 164  31 156  66 112  20  19 115 134  94  26  58\n",
      " 142  24  85  40  27   8  87  90  13   3 143  51  78 115 168  55  90  40\n",
      "  93  85 168   2 173  60   6 127  57 109 139 191 160  82 121 126  58 136\n",
      "  73 121 166  39  65  12 160 133 117 115 157 198   3  19  42 157  98 141\n",
      " 184  73  77  30  38 149  42 162 104  24   6  25 186 119 113  86   1  98\n",
      "   4   1 122  24  29 149  88  27 135 153  77 115  80 176 179 145  79   4\n",
      " 182  18  62  24 147  80  91 160 167  93 114 128 168  19 125  16 115  81\n",
      " 167 157 166 181  74 133 140  87  93  88  53 146  43  83   1  88 134  37\n",
      "  38 110 139 190  23 155  36 190 158  78 129 184  58  53  57 115  98 186\n",
      "  56  87 154  73  14  59  93  85 102  58  85 149  11  22 150 153 146 149\n",
      " 189  96 125 196   2  42  94 140 103  33 159  98  25  38 112   5  17  41\n",
      "  25  76  98 140  98  64  42 146 170 196  75  15 177  68  33  91 114  44\n",
      "  15 195  81 102 162  99  97  73  63  94  56 133  87 172  16 123  78 102\n",
      " 184 191  40  10  50  71 110 175 139  63  79 110  53 108 135 167  75 158\n",
      "  56 133  82 123  82 112  72 171  64  40 139 164  34 124 125 107  99  35\n",
      " 107  23 199 130 135 185  90 183  66 189 145  68 192 162  48  75  57  49\n",
      "  80 169  52 174 179 109 118  92  57 131 138  26  38  41  51  40 199 125\n",
      " 130 143  65 135 198 161 187  88  90  42 141  25 174 176 156  10 176  57\n",
      "  86  81 106 119  63 150  80 102 103  29 192 127  62 167 103  74 178  81\n",
      "  65 197  53 174  24 173  78 160  72  37 159  41 126 101 118 143  74  29\n",
      " 187  46 135 154  85 141  64  87  38  92 173   1 181 150 135 112 198 110\n",
      "  13  17 128 142  61  69  91  35 119 162  77 193 146 150  74 187  90  42\n",
      " 159  26 173  49 187 158 188 145 199 192 197 187 140 127 118 198 188 131\n",
      " 103  49  15 162  49 138 128  18  23  98 107  78  42  98 121  13  50  43\n",
      " 191  41  48 191 185 166  40 117  75 199  49  90  30  23 180 119  54 160\n",
      "  92   2  62 126 199  88  15  55  61 148 121  99 150 122  58  94 189 119\n",
      "  26 144  31  59  62  47  78 174 176 134  96  58   6 150  73 105 130  69\n",
      " 128  66 181  21 174   7 167  62  16  83 164  73 114  92 155  24  27  37\n",
      "  10 141  98 106  69   8 140 123 167  92  55 100 115   4   2 198 112   4\n",
      "  99  38 146 187 143  13  15 197 181  65  34  65 121 150 167 160 144  25\n",
      "  90 184  53 139  92  89   0  25  26 114  96 138  33 118  43 115 133 105\n",
      " 143 187  63 146 145  77  36  70   4  59]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=200, random_state=0).fit(user_features)\n",
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "completed, values, ind = compute_individual_dist(mini_tf, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "127.64959692955017\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "features = np.empty((ind.shape[0], ind.shape[1]**2*ind.shape[0]))\n",
    "delta_matrices_all = np.empty((ind.shape[0], ind.shape[0], ind.shape[1], ind.shape[1]))\n",
    "score_matrices_all = np.empty((ind.shape[0], ind.shape[0], ind.shape[1], ind.shape[1]))\n",
    "for user_index in range(values.shape[0]):\n",
    "    if user_index%100==0:\n",
    "        print(user_index)\n",
    "    #check for full joint distribution or add a prior later\n",
    "    if np.sum(ind[user_index]==0) > 0:\n",
    "        continue\n",
    "    #compute delta matrices with all other users where applicable\n",
    "    else:\n",
    "        #create a mask so that other half of tasks can be used later to find score matrix\n",
    "#         mask = np.random.randint(0,2,values.shape).astype(bool)\n",
    "        mask = np.ones((values.shape)).astype(bool)\n",
    "        delta_matrices, t_m_i_1, cluster_img = compute_deltas(user_index, completed, values, ind, mask, False, 20)\n",
    "        features[user_index,:] = cluster_img.flatten()\n",
    "        delta_matrices_all[user_index,:,:,:] = delta_matrices\n",
    "#         score_matrices, t_m_i_2 = compute_deltas(user_index, completed, values, ind, ~mask, True, 20)\n",
    "#         score_matrices_all[user_index,:,:,:] = score_matrices\n",
    "#         print(np.sum(t_m_i_1), np.sum(t_m_i_2))\n",
    "#         if len(np.intersect1d(np.array(np.where(t_m_i_1==True)), np.array(np.where(t_m_i_2==True))))>0:\n",
    "#             print(np.intersect1d(np.array(np.where(t_m_i_1==True)), np.array(np.where(t_m_i_2==True))))\n",
    "#             print(regret(score_matrices, delta_matrices, \\\n",
    "#                      np.logical_and((t_m_i_1==True), (t_m_i_2==True))))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110825"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_missing(X, n_clusters, max_iter=10):\n",
    "    \"\"\"Perform K-Means clustering on data with missing values.\n",
    "\n",
    "    Args:\n",
    "      X: An [n_samples, n_features] array of data to cluster.\n",
    "      n_clusters: Number of clusters to form.\n",
    "      max_iter: Maximum number of EM iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "      labels: An [n_samples] vector of integer labels.\n",
    "      centroids: An [n_clusters, n_features] array of cluster centroids.\n",
    "      X_hat: Copy of X with the missing values filled in.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize missing values to their column means\n",
    "    missing = ~np.isfinite(X)\n",
    "    mu = np.nanmean(X, 0, keepdims=1)\n",
    "    X_hat = np.where(missing, mu, X)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        print(i)\n",
    "        if i > 0:\n",
    "            # initialize KMeans with the previous set of centroids. this is much\n",
    "            # faster and makes it easier to check convergence (since labels\n",
    "            # won't be permuted on every iteration), but might be more prone to\n",
    "            # getting stuck in local minima.\n",
    "            cls = KMeans(n_clusters, init=prev_centroids)\n",
    "        else:\n",
    "            # do multiple random initializations in parallel\n",
    "            cls = KMeans(n_clusters, n_jobs=-1)\n",
    "\n",
    "        # perform clustering on the filled-in data\n",
    "        labels = cls.fit_predict(X_hat)\n",
    "        centroids = cls.cluster_centers_\n",
    "\n",
    "        # fill in the missing values based on their cluster centroids\n",
    "        X_hat[missing] = centroids[labels][missing]\n",
    "\n",
    "        # when the labels have stopped changing then we have converged\n",
    "        if i > 0 and np.all(labels == prev_labels):\n",
    "            break\n",
    "\n",
    "        prev_labels = labels\n",
    "        prev_centroids = cls.cluster_centers_\n",
    "\n",
    "    return labels, centroids, X_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annahilgard/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:893: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197  15  25 129   1  15  37  59  15  21  24  24   1  49 161  15   1  88\n",
      " 118 107   1   1  15  46   3   8   6  40  11  55  21 107  37 163  15   1\n",
      " 128 187  49 141  33  87 118 130 163   1 199  15   1  55  15   1  27  96\n",
      " 107  55  95  77  59   1   2  13  31  15  15   1  38 144 135  98  52  59\n",
      " 117  98  15  15  15  17 159  31  15  31  57  52  15  15  57  25  53 118\n",
      "  72  33  15  55  15 184  31 107 107 128   3  73  15  86  15  59   1   1\n",
      "  40  40  15  52 107  53  31  53   3   1   1 140 189  23  53 141 141  15\n",
      "  18  99  39  15  91  59  33 107   1  95  28 113 162  23  53 141  59  31\n",
      "  15  45  31  27  44 130  31  89  57  31  17  11  81  23  31  15  99  31\n",
      " 125   5  22  57 128  11  22  86 107   1   1 124 158  38  12   1   1  15\n",
      " 141  53 141 199  15  42   1   4  15  33   3  15  55  15 134  21  53   3\n",
      " 154 199  59   0  25 193   4  53 130 175  15  53   1  99 106   1  15  37\n",
      "   7  81 113   1 141 107  28 169 128  93  17  36   1   1   1 194  15 141\n",
      "   3  81   1  33  52  81  52  33  55  77  37 118 131  77  55 171  59  81\n",
      "  72 180 107 130  53   1  55   3   1 141 107 107  54  55  55  55  33  81\n",
      "  57   8  79   1 182 190  37  24   3 107  11  59 107  81  17 172  55  59\n",
      " 140   3  31  31  81  52 107  15   1  17  22  95 153   1   3 163   1  33\n",
      "  33 163   9 163 198 199  86 163   1  59  37 163  55  15 113  69 123   1\n",
      "  74   1 181  87  33  81  38  40   3 129 171  33  49 191  28  98  37 105\n",
      "  35 154   1  15  72 181  95  79 116  22  37 141  11  96  39 141  99  70\n",
      "  68   1  99 163  85   3  81  48  81 107 107   1  15  52 163   1 130   1\n",
      "   1 163  31  92 141  53  15   1 186  33 191   1  31   1 113 122  10  67\n",
      "  49 163  55   1  78  99  99 122  81   1 141  33  55   3  53  21 117   3\n",
      "  37  86  24 187 131 184   1  15  11 199  53  22  53  49 107   1  33  86\n",
      " 177   1  37  53   1  97  81 141  17  53   3   1   1   1  99   3   6  81\n",
      " 107 119  38  33  78  59  83   1   1  15   1  53 115 103   1 143  31  99\n",
      "  19  96  42 130 114 141  27  38 163  13   6   2   6  59  53  11  59 130\n",
      "   1  15  19 150   1   6 154 194 133  81  11  17   1 194  86  15 103  49\n",
      "   4  75 181  57  37   9  55 157  57  33   3 199  88  52  22  86  37  12\n",
      "  93  25  42  53 130  59  81 110  31   1 148  99  37  95  49   4   1   6\n",
      "  57  99 121  93  51 118  12  99  82 115   1 105  42   1   2  78  81   6\n",
      "  24   1   2 115  85  74 157  88  14  96 113  81  42  14 113  38  17  51\n",
      "  33  17  12  86  17 130  73  33 150 168   2   8  91   7   1  17   1  66\n",
      "  17  57  78  21  78  17  39  12 141   1  32  49 130 195  99   1 122  59\n",
      " 163   1   6  78  24 118 107  86  55  74  28  12 149  89 116   1  17  55\n",
      "   1  73  60  31  26   6 127 105  73  42   9 190  33  66  63  35  12   1\n",
      "  50  57   1  59  93 136 191 147  70   1 103 126   1 142 194  12   1  85\n",
      "  89   8  25  17 140  76   1 141 102  70  40 154  52 116 138  19 163  12\n",
      " 113 174  55  32 118  66 130  30  99  66   1  16  58  27  78  55  18  12\n",
      "  77  37  37 129  55  79 152 127 188  55  11  27   1  33 107 179  16  37\n",
      " 107   1  79  33  21  84 107 190 120  59 157   4 117   1  55  10  31 154\n",
      " 192   5  15   1  56  27  49  17   1   1  26   1  59  52   1   7 107  11\n",
      " 141 122   3 183 173 184  36  49  87 118  95 113   1 113  37  86  77   5\n",
      "  86 100 101  37  52  52  21   9  80 101 113  55 182   1  27 155   1 184\n",
      "  33  95  37   1  79 163  81   3  79   1 167   1 165  28 129  77  33  42\n",
      "  53  78 105  22  55  88  12 162  37 151  37  11  81 118  65  53 199   0\n",
      " 122   4 163  33  49 176   1  81  57   1  55  37   1  81  31  37  40 160\n",
      "  37  77  62  86   3  55 101  96  99 103  37   1  27  41   1  66  33 137\n",
      " 164  77 141   1 139  34  55  50  60  15  27  31 128  33 118  53   3  61\n",
      " 163  19 113   9  28  81   1   1  10  22  52  19  46   8 170  57 113  88\n",
      " 105  20   1  96 190  64   9  47  37   1   1   7 148  81 121 108 145   1\n",
      "  61  20  75  73  37   1 166 178  94 103 104  72  90  37 163  57  35  78\n",
      "   1  99 130  95   1 111  95  21   1   1 156   1 154   8  72   6 107   5\n",
      "  43 185  59 157 121  55  71  55  21   1   1  53 183  24  35   1  69 107\n",
      "   6 113   1 109 163  42  76 163 112  19  17  52   1   1 150  21 171 196\n",
      "  17  86 146  38   8  33 132  29  28 163]\n"
     ]
    }
   ],
   "source": [
    "labels, centroids, X_hat = kmeans_missing(features, 200, max_iter=5)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cluster_matrix_dist(labels, delta_matrices_all):\n",
    "#     delta_matrices_new=np.zeros((len(np.unique(labels)), len(np.unique(labels)), delta_matrices_all[0][0].shape[0], \\\n",
    "#                                                               delta_matrices_all[0][0].shape[1]))\n",
    "    delta_matrices_new=np.empty(delta_matrices_all.shape)\n",
    "    for i in np.unique(labels):\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        missing = ~np.isfinite(delta_matrices_all)\n",
    "        mu = np.nanmean(delta_matrices_all, 0, keepdims=0)\n",
    "        filled = np.where(missing, mu, delta_matrices_all)\n",
    "        cluster_i = np.average(filled[labels==i], axis=0)\n",
    "        for j in np.unique(labels): \n",
    "            if np.sum(np.sum(np.isnan(cluster_i), (1,2)))>0:\n",
    "                print(i,j)\n",
    "                missing = ~np.isfinite(deltas_used)\n",
    "                mu = np.nanmean(delta_matrices_all, 1, keepdims=1)\n",
    "                X_hat = np.where(missing, mu, X)\n",
    "            cluster_j = np.average(cluster_i[labels==j], axis=0)\n",
    "#             delta_matrices_new[i,j] = cluster_j\n",
    "            delta_matrices_new[np.ix_(labels==i,labels==j)] = cluster_j\n",
    "    return delta_matrices_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "delta_matrices_clust = calc_cluster_matrix_dist(labels, delta_matrices_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0776220916645\n"
     ]
    }
   ],
   "source": [
    "print(np.average([[pairwise_distances(score_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "0.0770279382517\n"
     ]
    }
   ],
   "source": [
    "delta_matrices_clust = calc_cluster_matrix_dist(kmeans.labels_, delta_matrices_all)\n",
    "print(np.average([[pairwise_distances(delta_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k_ in range(2,11):\n",
    "    model = Model(users, tasks, k=k_)\n",
    "    user_vec, user_bias = train(train_df, validate_df, test_df, model)\n",
    "    user_features = np.empty((user_vec.numpy().shape[0], user_vec.numpy().shape[1]+1))\n",
    "    user_features[:, :user_vec.numpy().shape[1]] = user_vec.numpy()\n",
    "    user_features[:, :-1] = user_bias.numpy()\n",
    "    kmeans = KMeans(n_clusters=200, random_state=0).fit(user_features)\n",
    "    delta_matrices_clust = calc_cluster_matrix_dist(kmeans.labels_, delta_matrices_all)\n",
    "    avg_dist = np.average([[pairwise_distances(delta_matrices_clust[i,j], delta_matrices_all[i,j]) for i in range(1000)] for j in range(1000)])\n",
    "    print(\"K={} score: {}\".format(k_, avg_dist))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
